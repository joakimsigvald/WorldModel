# Chapter 2 — Foundations

## 2.1. A Universe from Nothing: The Principle of Maximal Simplicity

We are attempting to describe and explain the world we live in, beyond what current physics can tell us. Since we have no direct access to whatever lies beneath today’s theoretical frameworks, we must search for a new starting point in the dark and climb step by step back up into the light, where existing physics and experiments can judge whether we are on the right track.

The only honest way to attempt this is to start with minimal assumptions and add structure only when it is strictly necessary. We might fail to find such a path, but if we succeed we will have a seed for a new theoretical framework that might reach all the way up to our current understanding of the world and beyond.

One motivation for such an ambitious undertaking is that fundamental physics seems stuck. No widely accepted breakthroughs have appeared since the Standard Model was completed in the 1970's. We still have not unified the two great theories of the twentieth century—quantum mechanics and general relativity—and we have no accepted way to incorporate the most important phenomenon known to man, or any life form: consciousness.

If we want to understand the world from the ground up, we therefore begin by assuming nothing: no space, no geometry, no shared time, no laws, and no quantities. From this absence of structure, the task is to identify the simplest form of “something” we can allow to exist without smuggling in the very structures we intend to explain.
## 2.2. Level-0: Pre-Form Chaos

Before the appearance of any stable form, we posit an initial state we call **Level-0**.  
This is a domain where nothing persists long enough to qualify as an entity. Patterns may momentarily arise, but they dissolve immediately. There is no continuity from one moment to the next, no stable relations, and no reliable structure.

At Level-0:

- configurations are transient,   
- interactions are uncoordinated,
- and no composite structure can take shape.

Level-0 is therefore a background of **unorganized fluctuation**, where nothing yet satisfies even the simplest requirements needed for structure to emerge. It marks the ontological boundary below which “being” has not yet crystallized into stable form.

From this state, the question becomes:

**What minimal conditions must be satisfied for a form to persist, to interact, and to participate in the buildup of more complex structures?**
## 2.3. The Minimal Conditions for the First Stable Forms

To rise out of Level-0, a form must satisfy the most basic requirements of persistence and interaction. We introduce only three such requirements—nothing more:

1. **Multiplicity** 
   There must exist more than one form. A universe containing only one form cannot generate structure, relations, or dynamics.

2. **Change**  
   Each form must be capable of internal change. Without internal variation, nothing can evolve, respond, or participate in processes.

3. **Connectivity**  
   Forms must be able to connect or interact. If no connections can form, no composite structures can arise, and complexity cannot accumulate.

These three conditions define the minimal threshold at which “something” can exist in a durable and interaction-capable sense. They do not yet specify what the first stable forms look like—only what they must be able to do.

In the next section, we introduce the simplest forms that satisfy these criteria. These will become the foundational building blocks of everything else in the model.
## 2.2. Bits: The Fundamental Unit of Existence
Given our starting point — multiple entities that can change internally and connect — we now specify the simplest possible form such an entity can take. We call it a **bit**.  

A bit has three defining properties:
### 2.2.1. Internal time

A bit proceeds through a sequence of internal updates.  
This is the minimal requirement for persistence or identity across its own evolution. Without internal time, an entity cannot change, interact, or take part in larger systems.

---
### 2.2.2. The internal state of a bit

One might assume that the simplest state change is a flip between “on” (1) and “off” (0), and this intuition partly motivates the name “bit.”  
But building discreteness into the fundamental layer of the model is incompatible with several basic phenomena we aim to describe later.  
The simplest continuous internal variable is a phase defined modulo 2π, which may evolve irregularly but always remains bounded.

This avoids arbitrary rules while giving the bit a minimal internal dynamic.  
The phase is entirely internal; it does not imply motion or spatial behavior.

---
### 2.2.3. A single external connection point

Each bit can form at most one connection with another bit at a time.  
This connection has no direction and carries no geometric information; two bits are simply connected or not.

This is the simplest possible form of interaction. As we will see, when combined with the hierarchical relations we will introduce next, it is sufficient to generate surprisingly rich structure.

---
This most minimal stage of order — entities with internal time, internal phase, and the ability to connect — constitutes **Level-1*: The lowest level of existence.

These three properties define the Level-1 bit. It is the smallest entity that can:
- exist through its own internal timeline,
- carry a minimal internal dynamic,
- and participate in constructing larger structures by forming pairs.
## 2.3. Synchronization

When two bits connect, their internal dynamics begin to interact.  
A bit’s internal phase may change irregularly, but a connection imposes mutual influence: each bit can sense the other’s current state, and each adjusts its updates accordingly. If their rhythms are too incompatible, the connection becomes strained.

The simplest and most stable pattern that two influencing phase-evolutions can settle into is a **regular, repeatable rhythm** with a **fixed frequency**. In this minimal setting, such rhythms take the form of a near-harmonic cycle with a well-defined update rate. Nothing in the model requires bits to exhibit this behavior on their own. Instead, it is a **collective effect of the connection itself**: synchronization pushes irregular patterns toward consistency.

Because synchronization is easier when rhythms are already compatible, bits with similar frequencies are statistically more likely to form a stable bond. One may imagine that such bits “see” each other more clearly. Beyond this tendency, the model offers no deeper mechanism for why particular bits connect: with no space, no forces, and no geometry at Level-1, bonding remains a primitive, unexplained event.

**Synchronization creates the first form of shared time.**
Before connection, each bit’s updates unfold along its own private timeline with no relation to any other. During connection, a consistent ordering emerges between the two update sequences. This shared timeline is purely relational and lasts only as long as the bond itself.

A bond breaks when the two bits can no longer maintain stable synchronization, or when one bit forms a new connection. Afterward, each bit resumes its independent evolution, losing the shared temporal structure established during the bond.

Over its lifetime, a bit may synchronize with many different partners.  
Each connection merges two previously independent timelines into a shared one, and when the bond dissolves, the bit carries forward the timing it adopted during that episode.  
As bits connect, separate, and reconnect in countless combinations, these merged timelines overlap and propagate through the population.  
In this way, many locally synchronized pairs collectively produce a broader, increasingly consistent temporal structure — the earliest precursor to a global notion of time.
## 2.4. Emergent Compounds: A new level of existence

Under certain conditions, when two connected bits form a highly synchronized and stable unit, a new entity may appear: a **compound**. This compound is not the two bits themselves, but an emergent structure that coexists with them on a higher level of existence. We call this compound a **couple**. Thus, two connected _bits_ on Level-0 may give rise to a unified _couple_ on Level-2.

Once the couple exists, it acquires its **own internal time and state**. Its state is an aggregate of its bits' states. The bits continue to have there own internal states and update rates, but they are now aligned with and constrained by the couple’s unified temporal structure.

With the emergence of the couple, each bit becomes internally bound to this new entity through a vertical relation that lets the couple act as a unified whole through its constituents. Once these vertical bonds take over the internal role of the former horizontal bond, that bond no longer adds anything useful and naturally dissolves. Freeing its connectors allows the bits to form new external bonds, so the couple has, in effect, two connectors and can form chains with other couples.

It is important to note that the only thing the couple can sense of the world outside itself is its two bits. The couple perceives and influences its surroundings only through them. So it is a useful simplification to say that the couple has two connector ports and can connect with other couples; in reality, only bits connect with bits.
## 2.5. Chains and Loops

**When couples form chains, they can take four logical forms:**
1. An **open chain**, where both ends have a free connector and the structure can be extended. 
2. A **semi-closed chain**, where one end is connected to a bit, such that no extension is possible from that end. 
3. A **fully closed chain**, where both ends are terminated by bits and no extension is possible. 
4. A **cyclic chain**, where the chain connects back onto itself and forms a ring."

**Only the fourth case is structurally significant.**  
A ring, being cyclically connected, imposes stronger synchronization pressures on its bits and couples than other chains do. If this heightened coherence can be achieved, the ring may stabilize into a level-3 entity: a **loop**.

When the loop emerges—with vertical bonds to its constituent couples—the horizontal bonds that held the ring together dissolve. The ring structure disappears, but the loop remains as a new unified entity with its own internal time and state, inherited from the coordinated activity of its constituent couples.

A loop is therefore not a ring-shaped object but a Level-2 subject whose internal organization is effectively a tree spanning three levels of existence:
* The root-node, the loop itself, resides on level-3
* The middle nodes, one for each couple, reside on level-2
* The leaf nodes, one for each bit, two per couple, reside on level-1

Although only bits connect directly at the fundamental level, we may speak of loops connecting to other loops whenever their constituent bits form bonds. This abstraction will be used throughout the rest of the book.
## 2.6. Loop Stability and Structural Tendencies

Loops are the first level of structure at which **closed synchronization constraints** arise. Unlike open chains, a loop imposes global consistency conditions on the internal timing and phase relations of its constituent couples. This makes loops both powerful and fragile: they can store structure, but they are also subject to internal strain.

Several general tendencies follow from this observation.

First, **shorter loops are structurally favored**. As loop size increases, the number of vertical bonds and synchronization constraints grows, increasing the probability that one constraint fails and destabilizes the whole structure. While loops of arbitrary length may form transiently, longer loops are increasingly fragile and tend to fragment into smaller loops.

Second, **redundant internal bonds tend to dissolve**. If two couples are already connected indirectly through the loop structure, a remaining direct horizontal bond no longer contributes to stability and instead adds strain. The system therefore tends to eliminate redundant horizontals, freeing connectors for external interaction.

Third, loop populations exhibit a preference for **structural diversity**. Regions dominated by a single loop type are dynamically poor: they offer fewer reconfiguration pathways and tend to trap strain. Introducing loops of a different size often reduces overall strain by opening alternative synchronization patterns and connector usages. This creates a pressure away from uniformity and toward mixed loop populations.

Finally, not all loop sizes are equally viable. Very short loops lack sufficient degrees of freedom, while very long loops are too fragile. This suggests that only a small subset of loop sizes can persist as long-lived species, while others function primarily as transient intermediates.

These qualitative tendencies do not yet define precise dynamics, but they strongly constrain which loop structures can play a lasting role in the buildup of higher-order organization.
## 2.7. Energy as Strain

In this framework, **energy is not a primitive quantity**, but a derived measure of **structural strain**.

Strain arises whenever a structure must maintain incompatible or sub-optimal constraints. There are two primary sources:

1. **Phase strain**, resulting from the effort required to keep multiple internal rhythms synchronized under fixed offsets.
    
2. **Connector strain**, resulting from constrained or redundant use of available connectors.
    
A perfectly relaxed structure is one in which synchronization is easy and connector usage is minimal and non-redundant. Any deviation from this ideal stores strain, and that stored strain is what we call energy.

This definition unifies several familiar notions:

- kinetic energy corresponds to strain associated with maintaining coordinated updates under motion-like reconfiguration,
    
- potential energy corresponds to strain associated with constrained configurations,
    
- binding energy corresponds to the release of strain when redundant or conflicting constraints dissolve.
    
Importantly, strain is **local and structural**. It is not conserved as an abstract scalar but redistributed as structures rearrange. When a strained structure breaks apart or reconfigures, strain is released and appears elsewhere as increased activity, motion, or the formation of new structures.

This notion of energy provides a common language for describing why certain loop configurations persist, why others decay, and why reconfiguration pathways have preferred directions.
## 2.8 Loop Chemistry

The qualitative tendencies described above can be captured in a deliberately simplified *loop-chemistry model*. The aim of this model is not to describe the full microscopic dynamics of loops, but to test whether a small set of natural assumptions is sufficient to produce a stable equilibrium among loop types.

The model treats loops as a population of interacting species that locally re-partition existing structure through reversible reactions, biased only by structural strain. 

### 2.8.1 Loop species and conservation

We consider only three loop species:

- 3-loops (three couples)
- 4-loops (four couples)
- 5-loops (five couples)

Loops larger than five couples are assumed to be structurally fragile and to fragment rapidly into smaller loops. They therefore do not appear as long-lived species in the model.

2-loops are assumed to be strongly disfavored by the redundancy reducing tendency among chains, since it would arise from only two couples with double horizontal bounds between them. Thus, we assume that 2-loops never appear.

All reactions conserve the total number of couples. Loop chemistry is a repackaging of existing structure, not the creation or destruction of constituents.

Let:

- n3, n4, n5 be the counts of 3-, 4-, and 5-loops
- N = n3 + n4 + n5 be the total number of loops
- p3 = n3 / N, p4 = n4 / N, p5 = n5 / N be the corresponding proportions

The conserved quantity is:

3·n3 + 4·n4 + 5·n5 = C

where C is the total number of couples.

### 2.8.2 Allowed reversible reactions

We allow three reversible local reactions, chosen as the smallest non-trivial re-partitionings that conserve couples:

- [3,3,3] <-> [4,5]
- [4,4] <-> [3,5]
- [5,5] <-> [3,3,4]

Each reaction rearranges a small neighborhood of loops while preserving the total number of couples involved.

### 2.8.3 Encounter factors

As a mean-field approximation, the availability of a given multiset of loops is assumed to scale with the product of their proportions:

- [i,i] occurs with weight p_i^2
- [i,j] with weight 2·p_i·p_j for i ≠ j
- [i,i,i] with weight p_i^3
- [3,3,4] with weight 3·p3^2·p4

These encounter factors encode only combinatorics and mixing, not preference.

### 2.8.4 Structural cost (strain)

Each multiset of loops is assigned a scalar cost representing combined phase strain and redundancy.

The cost is defined as:

E(X) = S_total(X) + D(X)

Where:

- D(X) = number of elements in X minus number of distinct loop types in X
- S_total(X) is the sum of per-loop synchronization costs

Per-loop synchronization costs are assigned according to the rule:

- S(n) = 2^(n−3)

So in particular:

- S(3) = 1
- S(4) = 2
- S(5) = 4

This rule reflects the assumption that each additional couple in a loop approximately doubles the number of independent phase-consistency constraints that must be maintained. The precise exponential form is not essential; what matters is that synchronization strain grows rapidly with loop size, making larger loops increasingly costly and therefore less stable.

The resulting costs for the multisets appearing in the reactions are:

| Multiset | Cost |
| -------- | ---- |
| [3,3,3]  | 5    |
| [4,5]    | 6    |
| [4,4]    | 5    |
| [3,5]    | 5    |
| [5,5]    | 9    |
| [3,3,4]  | 5    |

### 2.8.5 Reaction rates

Reactions are biased smoothly toward lower total cost but remain fully reversible.

For a reaction R <-> P:

- rate(R -> P) = B(R) · exp( − (E(P) − E(R)) / 2 )
- rate(P -> R) = B(P) · exp( − (E(R) − E(P)) / 2 )

where B(·) is the encounter factor.

Lower-strain configurations are favored, but higher-strain transitions remain possible.

### 2.8.6 Equilibrium condition

For each reaction define the net flux:

J = forward_rate − backward_rate

The loop counts evolve according to reaction stoichiometry. Equilibrium is defined as the absence of net production or consumption of any loop type:

dn3/dt = dn4/dt = dn5/dt = 0

In this model, this condition is equivalent to:

J1 = J2 = J3

Together with p3 + p4 + p5 = 1, this system has a unique interior solution.

### 2.8.7 Numerical equilibrium and connector count

Solving the equilibrium equations yields approximately:

- p3 ≈ 0.57
- p4 ≈ 0.34
- p5 ≈ 0.09

Interpreting loop sizes as exposing:

- 6 connectors for 3-loops
- 8 connectors for 4-loops
- 10 connectors for 5-loops

the resulting average connector count is:

average_connectors = 6·p3 + 8·p4 + 10·p5 ≈ 7.04

This value is not imposed by construction. It emerges solely from the reaction set, conservation of couples, and smooth bias toward reduced strain. Given the simplicity of the model, the number should be regarded as approximate rather than exact.

The rule-of-thumb takeaway is that loops tend to react and reconfigure in a way that reaches an equilibrium of about **7 connectors per loop**.
